{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18BCE101\n",
    "## Practical 7\n",
    "## Aim:\n",
    "Classify a given text data into predetermined categories. You can choose (i) Spam mail classification or (ii) News article classification examples.\n",
    " \n",
    "Given a set of labeled email documents, classify them as spam or non-spam using Naive Bayesian classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import random\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk import NaiveBayesClassifier, classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading the files and categorizing the content as spam/ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(start_path):\n",
    "    a_list = []\n",
    "    for path,dirs,files in os.walk(start_path):\n",
    "        for filename in files:\n",
    "            f = open(os.path.join(path,filename), 'r', encoding=\"latin1\")\n",
    "            a_list.append(f.read())\n",
    "        f.close()\n",
    "    return a_list\n",
    "\n",
    "#Loading the data\n",
    "spam = read_files('data/spam/')\n",
    "ham = read_files('data/ham/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emails = [(email, 'spam') for email in spam]\n",
    "all_emails += [(email, 'ham') for email in ham]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Subject: dobmeos with hgh my energy level has gone up ! stukm\\nintroducing\\ndoctor - formulated\\nhgh\\nhuman growth hormone - also called hgh\\nis referred to in medical science as the master hormone . it is very plentiful\\nwhen we are young , but near the age of twenty - one our bodies begin to produce\\nless of it . by the time we are forty nearly everyone is deficient in hgh ,\\nand at eighty our production has normally diminished at least 90 - 95 % .\\nadvantages of hgh :\\n- increased muscle strength\\n- loss in body fat\\n- increased bone density\\n- lower blood pressure\\n- quickens wound healing\\n- reduces cellulite\\n- improved vision\\n- wrinkle disappearance\\n- increased skin thickness texture\\n- increased energy levels\\n- improved sleep and emotional stability\\n- improved memory and mental alertness\\n- increased sexual potency\\n- resistance to common illness\\n- strengthened heart muscle\\n- controlled cholesterol\\n- controlled mood swings\\n- new hair growth and color restore\\nread\\nmore at this website\\nunsubscribe\\n',\n",
       "  'spam'),\n",
       " ('Subject: your prescription is ready . . oxwq s f e\\nlow cost prescription medications\\nsoma , ultram , adipex , vicodin many more\\nprescribed online and shipped\\novernight to your door ! !\\none of our us licensed physicians will write an\\nfda approved prescription for you and ship your\\norder overnight via a us licensed pharmacy direct\\nto your doorstep . . . . fast and secure ! !\\nclick here !\\nno thanks , please take me off your list\\nogrg z\\nlqlokeolnq\\nlnu',\n",
       "  'spam'),\n",
       " ('Subject: get that new car 8434\\npeople nowthe weather or climate in any particular environment can change and affect what people eat and how much of it they are able to eat .',\n",
       "  'spam')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_emails[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5172"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly shuffle the spam and ham examples\n",
    "random.shuffle(all_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\labdh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess(sentence):\n",
    "    return [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text, setting):\n",
    "    #bow - bag of words\n",
    "    if setting=='bow':\n",
    "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [(get_features(email, 'bow'), label) for (email, label) in all_emails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'subject': 1,\n",
       "   ':': 3,\n",
       "   'txu': 9,\n",
       "   'lone': 4,\n",
       "   'star': 4,\n",
       "   'working': 1,\n",
       "   'clearing': 1,\n",
       "   'old': 1,\n",
       "   '/': 7,\n",
       "   'gas': 5,\n",
       "   'distribution': 1,\n",
       "   'balance': 1,\n",
       "   '8': 4,\n",
       "   '99': 4,\n",
       "   '9': 2,\n",
       "   '.': 13,\n",
       "   'originally': 2,\n",
       "   'billed': 1,\n",
       "   'nominated': 1,\n",
       "   'quantity': 1,\n",
       "   'shortpaid': 1,\n",
       "   'u': 1,\n",
       "   'due': 1,\n",
       "   'meter': 2,\n",
       "   'adjustment': 1,\n",
       "   'brokered': 2,\n",
       "   'deal': 10,\n",
       "   'sold': 2,\n",
       "   'purchased': 2,\n",
       "   'exxonmobil': 5,\n",
       "   'highland': 5,\n",
       "   'ha': 1,\n",
       "   'provided': 1,\n",
       "   'support': 1,\n",
       "   'since': 2,\n",
       "   'pipeline': 1,\n",
       "   ',': 12,\n",
       "   'however': 1,\n",
       "   'unsure': 1,\n",
       "   'volume': 1,\n",
       "   'management': 1,\n",
       "   'reallocate': 1,\n",
       "   'example': 1,\n",
       "   '10': 1,\n",
       "   '000': 1,\n",
       "   'mmbtu': 4,\n",
       "   '3': 2,\n",
       "   '1': 1,\n",
       "   '200': 1,\n",
       "   'energy': 3,\n",
       "   '800': 1,\n",
       "   'show': 1,\n",
       "   'total': 1,\n",
       "   'amount': 1,\n",
       "   'wa': 2,\n",
       "   '240': 1,\n",
       "   'purchase': 3,\n",
       "   'piece': 1,\n",
       "   'allocated': 1,\n",
       "   '?': 1,\n",
       "   'august': 1,\n",
       "   '1999': 2,\n",
       "   'sale': 2,\n",
       "   'electric': 2,\n",
       "   '&': 2,\n",
       "   '#': 7,\n",
       "   '104975': 1,\n",
       "   '104256': 1,\n",
       "   '104738': 1,\n",
       "   'co': 3,\n",
       "   '101985': 1,\n",
       "   'corp': 2,\n",
       "   '101522': 2,\n",
       "   '101530': 2,\n",
       "   'september': 1,\n",
       "   '109046': 1,\n",
       "   '108564': 1,\n",
       "   '108146': 1,\n",
       "   'please': 1,\n",
       "   'let': 1,\n",
       "   'know': 1,\n",
       "   'need': 1,\n",
       "   'speak': 1,\n",
       "   'someone': 1,\n",
       "   'else': 1,\n",
       "   'thanks': 2,\n",
       "   'help': 1,\n",
       "   'rebecca': 1},\n",
       "  'ham'),\n",
       " ({'subject': 1,\n",
       "   ':': 1,\n",
       "   'union': 2,\n",
       "   'carbide': 2,\n",
       "   '-': 2,\n",
       "   'seadrift': 2,\n",
       "   'hpl': 1,\n",
       "   'meter': 2,\n",
       "   '#': 3,\n",
       "   '1332': 2,\n",
       "   'month': 1,\n",
       "   ',': 3,\n",
       "   'volume': 1,\n",
       "   'sitara': 1,\n",
       "   '380578': 1,\n",
       "   'instead': 1,\n",
       "   'overflowing': 1,\n",
       "   'swing': 1,\n",
       "   'ticket': 1,\n",
       "   \"'\": 2,\n",
       "   'gas': 1,\n",
       "   'daily': 1,\n",
       "   'priced': 1,\n",
       "   'deal': 1,\n",
       "   'question': 1,\n",
       "   '3': 1,\n",
       "   '.': 1,\n",
       "   '5923': 1,\n",
       "   'thanks': 1},\n",
       "  'ham'),\n",
       " ({'subject': 2,\n",
       "   ':': 7,\n",
       "   'nom': 4,\n",
       "   'change': 4,\n",
       "   'new': 2,\n",
       "   'well': 2,\n",
       "   'haynes': 2,\n",
       "   '21': 2,\n",
       "   'tejas': 2,\n",
       "   'effective': 1,\n",
       "   '6': 1,\n",
       "   '/': 8,\n",
       "   '27': 1,\n",
       "   '2000': 3,\n",
       "   '-': 50,\n",
       "   'forwarded': 1,\n",
       "   'beverly': 1,\n",
       "   'beaty': 1,\n",
       "   'hou': 1,\n",
       "   'ect': 1,\n",
       "   '06': 2,\n",
       "   '26': 2,\n",
       "   '08': 1,\n",
       "   '11': 1,\n",
       "   'enron': 2,\n",
       "   'capital': 1,\n",
       "   '&': 1,\n",
       "   'trade': 1,\n",
       "   'resource': 1,\n",
       "   'corp': 1,\n",
       "   '.': 3,\n",
       "   '``': 2,\n",
       "   'jan': 1,\n",
       "   'svajian': 1,\n",
       "   '07': 1,\n",
       "   '52': 1,\n",
       "   'cc': 1,\n",
       "   'see': 1,\n",
       "   'attached': 1,\n",
       "   'xl': 1},\n",
       "  'ham')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, samples_proportion):\n",
    "    train_size = int(len(features) * samples_proportion)\n",
    "    train_set, test_set = features[:train_size], features[train_size:]\n",
    "    print ('Training set size = ' + str(len(train_set)) + ' emails')\n",
    "    print ('Test set size = ' + str(len(test_set)) + ' emails')\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size = 4137 emails\n",
      "Test set size = 1035 emails\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train(all_features, 0.8)\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evauating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_set, test_set, classifier):\n",
    "    print ('Accuracy on the training set = ' + str(classify.accuracy(classifier, train_set)))\n",
    "    print ('Accuracy of the test set = ' + str(classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set = 0.9584239787285472\n",
      "Accuracy of the test set = 0.9314009661835749\n"
     ]
    }
   ],
   "source": [
    "evaluate(train_set, test_set, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               forwarded = 1                 ham : spam   =    145.6 : 1.0\n",
      "            prescription = 1                spam : ham    =     94.3 : 1.0\n",
      "                     nom = 1                 ham : spam   =     92.8 : 1.0\n",
      "                      xl = 2                 ham : spam   =     89.0 : 1.0\n",
      "                    pain = 1                spam : ham    =     87.9 : 1.0\n",
      "                   brand = 1                spam : ham    =     79.8 : 1.0\n",
      "                    2005 = 1                spam : ham    =     73.4 : 1.0\n",
      "                   meter = 1                 ham : spam   =     71.6 : 1.0\n",
      "                      ex = 1                spam : ham    =     65.4 : 1.0\n",
      "                     ibm = 1                spam : ham    =     62.1 : 1.0\n",
      "                creative = 1                spam : ham    =     62.1 : 1.0\n",
      "               trademark = 1                spam : ham    =     60.5 : 1.0\n",
      "                     sex = 1                spam : ham    =     57.3 : 1.0\n",
      "                      cc = 2                 ham : spam   =     56.8 : 1.0\n",
      "                congress = 1                spam : ham    =     55.7 : 1.0\n",
      "              nomination = 1                 ham : spam   =     54.0 : 1.0\n",
      "             legislation = 1                spam : ham    =     52.4 : 1.0\n",
      "               complaint = 1                spam : ham    =     52.4 : 1.0\n",
      "                     971 = 2                spam : ham    =     52.4 : 1.0\n",
      "                    sony = 1                spam : ham    =     52.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Classification is involved in many tasks in machine learning.\n",
    "Spam filtering is a binary classification task where you need to detect whether an email belongs to a “spam” or “ham” class and thus we have used Bernouli Naive Bayes classification method here.\n",
    "Word occurrence and frequency are some of the most informative features for spam detection.\n",
    "We preprocess the data before using words as features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
